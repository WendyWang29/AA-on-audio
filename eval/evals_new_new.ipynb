{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:09:24.543742Z",
     "start_time": "2024-09-30T09:09:15.762146Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import *\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to extract the numeric part of the filename (after the last underscore and before the file extension)\n",
    "def extract_numeric_part(path):\n",
    "    # This regex extracts the number after the last underscore and before the file extension (.flac)\n",
    "    match = re.search(r'_(\\d+)\\.flac$', path)\n",
    "    if match:\n",
    "        return match.group(1)  # Return only the numeric part\n",
    "    return None  # Return None if the pattern doesn't match\n",
    "\n",
    "\n",
    "def pred_and_labels_clean(file1_csv, file2_csv):\n",
    "    '''\n",
    "    file1: probabilities list .csv\n",
    "    file2: eval dataset .csv\n",
    "    '''\n",
    "    \n",
    "    prediction_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    # Step 1: Read file2 into a dictionary for quick look-up based on the numeric part of the file path\n",
    "    file2_dict = {}\n",
    "    with open(file2_csv, mode='r') as file2:\n",
    "        reader = csv.DictReader(file2)\n",
    "        for row in reader:\n",
    "            numeric_file2 = extract_numeric_part(row['path'])\n",
    "            if numeric_file2:\n",
    "                file2_dict[numeric_file2] = row['label']\n",
    "\n",
    "    # Step 2: Traverse file1 and check against file2 dictionary, using tqdm for progress tracking\n",
    "    with open(file1_csv, mode='r') as file1:\n",
    "        reader = csv.DictReader(file1)\n",
    "        total_rows = sum(1 for _ in open(file1_csv)) - 1  # Calculate total rows for the progress bar (excluding header)\n",
    "    \n",
    "        file1.seek(0)  # Reset the reader position back to the start of the file after counting\n",
    "        for row in reader:\n",
    "            # Extract the numeric part from file1's path\n",
    "            file1_path = row['Filename']\n",
    "            numeric_file1 = extract_numeric_part(file1_path)\n",
    "        \n",
    "            # Step 3: Check if the numeric part exists in the file2 dictionary\n",
    "            if numeric_file1 and numeric_file1 in file2_dict:\n",
    "                pred_class_0 = float(row['Pred.class 0'])\n",
    "                pred_class_1 = float(row['Pred.class 1'])\n",
    "            \n",
    "                # Step 4: Append prediction based on comparison\n",
    "                prediction_list.append(0 if pred_class_0 > pred_class_1 else 1)\n",
    "            \n",
    "                # Step 5: Append the corresponding label from file2\n",
    "                label_list.append(int(file2_dict[numeric_file1]))\n",
    "\n",
    "    \n",
    "    return prediction_list, label_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pred_and_labels_attack(file1_csv, file2_csv):\n",
    "    \n",
    "    def extract_numeric_part(path):\n",
    "        # This regex captures the numeric part following 'LA_E_' and stops at the next underscore or period\n",
    "        match = re.search(r'LA_E_(\\d+)', path)\n",
    "        if match:\n",
    "            return match.group(1)  # Return only the numeric part\n",
    "        return None  # Return None if the pattern doesn't match\n",
    "    \n",
    "    prediction_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    # Step 1: Read file2 into a dictionary for quick look-up based on the numeric part of the file path\n",
    "    file2_dict = {}\n",
    "    with open(file2_csv, mode='r') as file2:\n",
    "        reader = csv.DictReader(file2)\n",
    "        for row in reader:\n",
    "            numeric_file2 = extract_numeric_part(row['path'])\n",
    "            if numeric_file2:\n",
    "                file2_dict[numeric_file2] = row['label']\n",
    "\n",
    "    # Step 2: Traverse file1 and check against file2 dictionary, using tqdm for progress tracking\n",
    "    with open(file1_csv, mode='r') as file1:\n",
    "        reader = csv.DictReader(file1)\n",
    "        total_rows = sum(1 for _ in open(file1_csv)) - 1  # Calculate total rows for the progress bar (excluding header)\n",
    "    \n",
    "        file1.seek(0)  # Reset the reader position back to the start of the file after counting\n",
    "        for row in reader:\n",
    "            # Extract the numeric part from file1's path\n",
    "            file1_path = row['Filename']\n",
    "            numeric_file1 = extract_numeric_part(file1_path)\n",
    "        \n",
    "            # Step 3: Check if the numeric part exists in the file2 dictionary\n",
    "            if numeric_file1 and numeric_file1 in file2_dict:\n",
    "                pred_class_0 = float(row['Pred.class 0'])\n",
    "                pred_class_1 = float(row['Pred.class 1'])\n",
    "            \n",
    "                # Step 4: Append prediction based on comparison\n",
    "                prediction_list.append(0 if pred_class_0 > pred_class_1 else 1)\n",
    "            \n",
    "                # Step 5: Append the corresponding label from file2\n",
    "                label_list.append(int(file2_dict[numeric_file1]))\n",
    "\n",
    "    \n",
    "    return prediction_list, label_list\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:09:24.559743Z",
     "start_time": "2024-09-30T09:09:24.546032Z"
    }
   },
   "id": "764114fe1a692152",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_clean(eval_model, model_version, type_of_spec, feature, dataset):\n",
    "    \n",
    "    script_dir = os.getcwd()  # get directory of current script\n",
    "    print('Evaluating clean dataset...')\n",
    "    probs_csv = f'probs_{eval_model}_{model_version}_clean_{dataset}_{type_of_spec}_{feature}.csv'\n",
    "    #probs = pd.read_csv(os.path.join(script_dir, probs_csv), header=0, engine='python')\n",
    "    \n",
    "    if dataset == '3s':\n",
    "        eval_csv = os.path.join(os.path.dirname(script_dir), 'data', 'df_eval_19_3s.csv' )\n",
    "    else:\n",
    "        eval_csv = os.path.join(os.path.dirname(script_dir), 'data', 'df_eval_19.csv' )\n",
    "\n",
    "\n",
    "    pred_labels, GT_labels = pred_and_labels_clean(file1_csv=probs_csv, file2_csv=eval_csv)\n",
    "    \n",
    "    print(len(pred_labels))\n",
    "    print(len(GT_labels))\n",
    "\n",
    "    # UNBALANCED ACCURACY\n",
    "    UA = accuracy_score(y_true=GT_labels, y_pred=pred_labels)\n",
    "    BA = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels)\n",
    "\n",
    "    print(f'Eval model: {eval_model} {model_version}, clean dataset: {dataset}, feature = {feature} --> UA = {UA*100:.2f}%, BA = {BA*100:.2f}% ')\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:09:24.575364Z",
     "start_time": "2024-09-30T09:09:24.561342Z"
    }
   },
   "id": "4e29dca2f7faf26b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def eval_attack(attack, eval_model, attack_model, model_version, type_of_spec, feature, dataset, epsilon, q_res, q_sen):\n",
    "    \n",
    "    epsilon_str = str(epsilon).replace('.', 'dot')\n",
    "    script_dir = os.getcwd()  # get directory of current script\n",
    "    \n",
    "    if attack != 'Ensemble' and attack != None:\n",
    "        probs_csv = f'probs_{eval_model}_{model_version}_{attack}_{attack_model}_{dataset}_{epsilon_str}_{type_of_spec}_{feature}.csv'\n",
    "        probs = pd.read_csv(os.path.join(script_dir, probs_csv), header=0, engine='python')\n",
    "    elif attack == 'Ensemble':\n",
    "        probs_csv = f'probs_{eval_model}_{model_version}_Ensemble_{dataset}_{q_res}_{q_sen}_{epsilon_str}_{type_of_spec}_{feature}.csv'\n",
    "        probs = pd.read_csv(os.path.join(script_dir, probs_csv), header=0, engine='python')\n",
    "\n",
    "    # GT labels\n",
    "    if dataset == '3s':\n",
    "        eval_csv = os.path.join(os.path.dirname(script_dir), 'data', 'df_eval_19_3s.csv' )\n",
    "    else:\n",
    "        eval_csv = os.path.join(os.path.dirname(script_dir), 'data', 'df_eval_19.csv' )\n",
    "        \n",
    "\n",
    "    pred_labels, GT_labels = pred_and_labels_attack(file1_csv=probs_csv, file2_csv=eval_csv)\n",
    "    \n",
    "    #print(len(pred_labels))\n",
    "    #print(len(GT_labels))\n",
    "\n",
    "    # UNBALANCED ACCURACY\n",
    "    UA = accuracy_score(y_true=GT_labels, y_pred=pred_labels)\n",
    "    BA = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels)\n",
    "    \n",
    "    if attack != 'Ensemble':    \n",
    "        print(f'Eval model: {eval_model} {model_version}, attack: {attack}, attack model: {attack_model} {model_version}, dataset: {dataset}, eps={epsilon}, feature = {feature} --> UA = {UA*100:.2f}%, BA = {BA*100:.2f}% ')\n",
    "    elif attack == 'Ensemble':\n",
    "        print(f'Eval model: {eval_model} {model_version}, attack: Ensemble, q_res = {q_res}, q_sen = {q_sen}, dataset: {dataset}, eps={epsilon}, feature = {feature} --> UA = {UA*100:.2f}%, BA = {BA*100:.2f}% ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:09:24.585894Z",
     "start_time": "2024-09-30T09:09:24.577672Z"
    }
   },
   "id": "f5b9d3e910b3a8f9",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Clean dataset with magnitude"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b693cbb1669d921"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating clean dataset...\n",
      "71237\n",
      "71237\n",
      "Eval model: ResNet v0, clean dataset: whole, feature = audio --> UA = 89.45%, BA = 49.89% \n"
     ]
    }
   ],
   "source": [
    "eval_clean(eval_model='ResNet', model_version='v0', type_of_spec='mag', feature='audio', dataset='whole')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:27:21.430317Z",
     "start_time": "2024-09-30T09:27:19.906940Z"
    }
   },
   "id": "1f93ec7ffe26ef00",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Clean dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce5d8c10e8f59010"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating clean dataset...\n",
      "71237\n",
      "71237\n",
      "Eval model: ResNet v0, clean dataset: whole, feature = audio --> UA = 89.45%, BA = 49.89% \n"
     ]
    }
   ],
   "source": [
    "eval_clean(eval_model='ResNet', model_version='v0', type_of_spec='pow', feature='audio', dataset='whole')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:09:25.787660Z",
     "start_time": "2024-09-30T09:09:24.587439Z"
    }
   },
   "id": "e1fbda93ed7cd98e",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating clean dataset...\n",
      "71237\n",
      "71237\n",
      "Eval model: SENet v0, clean dataset: whole, feature = audio --> UA = 70.80%, BA = 82.62% \n"
     ]
    }
   ],
   "source": [
    "eval_clean(eval_model='SENet', model_version='v0', type_of_spec='pow', feature='audio', dataset='whole')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:31:04.237666Z",
     "start_time": "2024-09-30T09:31:02.515247Z"
    }
   },
   "id": "c761360f57da0d60",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Whole dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "109cca32287234fc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval model: ResNet v0, attack: FGSM, attack model: ResNet v0, dataset: whole, eps=3.0, feature = audio --> UA = 1.39%, BA = 0.82% \n",
      "Eval model: ResNet v0, attack: FGSM, attack model: ResNet v0, dataset: whole, eps=3.0, feature = spec --> UA = 0.00%, BA = 0.00% \n"
     ]
    }
   ],
   "source": [
    "eval_attack(attack='FGSM', eval_model='ResNet', attack_model='ResNet', model_version='v0', type_of_spec='pow', feature='audio', dataset='whole', epsilon=3.0, q_res=None, q_sen=None)\n",
    "eval_attack(attack='FGSM', eval_model='ResNet', attack_model='ResNet', model_version='v0', type_of_spec='pow', feature='spec', dataset='whole', epsilon=3.0, q_res=None, q_sen=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:20:47.097711Z",
     "start_time": "2024-09-30T09:20:44.247011Z"
    }
   },
   "id": "407a676e8625e9f7",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval model: SENet v0, attack: FGSM, attack model: SENet v0, dataset: whole, eps=3.0, feature = audio --> UA = 13.50%, BA = 25.57% \n",
      "Eval model: SENet v0, attack: FGSM, attack model: SENet v0, dataset: whole, eps=3.0, feature = spec --> UA = 9.24%, BA = 5.15% \n"
     ]
    }
   ],
   "source": [
    "eval_attack(attack='FGSM', eval_model='SENet', attack_model='SENet', model_version='v0', type_of_spec='pow', feature='audio', dataset='whole', epsilon=3.0, q_res=None, q_sen=None)\n",
    "eval_attack(attack='FGSM', eval_model='SENet', attack_model='SENet', model_version='v0', type_of_spec='pow', feature='spec', dataset='whole', epsilon=3.0, q_res=None, q_sen=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T09:21:06.759324Z",
     "start_time": "2024-09-30T09:21:01.271939Z"
    }
   },
   "id": "41864d41bedf7c69",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "33bb96734c58514a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation scores\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e72e876c1cd569fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "example: <br>\n",
    "higher log probability ==> predicted class\n",
    "if [score 0]=-2 and [score 1]=-3 then it means that the predicted class is class 0 <br>\n",
    "[score] = -2+3 = 1 > 0 --> class 0\n",
    "<br>\n",
    "###########\n",
    "<br>\n",
    "if [score 0]=-3 and [score 1]=-2 then it means that the predicted class is class 1 <br>\n",
    "[score] = -3+2 = -1 < 0 --> class 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91fad8d613b40b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Load the scores"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e997dc3e96b5904"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.utils import *\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_curve, auc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:30:37.772910Z",
     "start_time": "2024-06-05T20:30:20.079122Z"
    }
   },
   "id": "142b35be13b9255",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "probs_rawnet_clean_csv = '../eval/prob_rawnet_eval.csv'\n",
    "probs_rawnet_clean = pd.read_csv(probs_rawnet_clean_csv, header=0, engine='python')\n",
    "\n",
    "probs_rawnet_0dot2_csv = '../eval/prob_rawnet_eval_FGSM_0dot2.csv'\n",
    "probs_rawnet_0dot2 = pd.read_csv(probs_rawnet_0dot2_csv, header=0, engine='python')\n",
    "\n",
    "probs_rawnet_1dot0_csv = '../eval/prob_rawnet_eval_FGSM_1dot0.csv'\n",
    "probs_rawnet_1dot0 = pd.read_csv(probs_rawnet_1dot0_csv, header=0, engine='python')\n",
    "\n",
    "probs_rawnet_2dot0_csv = '../eval/prob_rawnet_eval_FGSM_2dot0.csv'\n",
    "probs_rawnet_2dot0 = pd.read_csv(probs_rawnet_2dot0_csv, header=0, engine='python')\n",
    "\n",
    "probs_rawnet_3dot0_csv = '../eval/prob_rawnet_eval_FGSM_3dot0.csv'\n",
    "probs_rawnet_3dot0 = pd.read_csv(probs_rawnet_3dot0_csv, header=0, engine='python')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:30:41.721359Z",
     "start_time": "2024-06-05T20:30:37.778611Z"
    }
   },
   "id": "36dd3023a736ac27",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Lengths are not okay",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m Lengths are not okay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/home/wwang/miniconda3/envs/thesis/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# paths to csv score files\n",
    "probs_clean_csv = '../eval/prob_resnet_spec_eval.csv'\n",
    "probs_0dot0_csv = '../eval/prob_resnet_spec_eval_FGSM_0dot0.csv'\n",
    "probs_0dot2_csv = '../eval/prob_resnet_spec_eval_FGSM_0dot2.csv'\n",
    "probs_0dot4_csv = '../eval/prob_resnet_spec_eval_FGSM_0dot4.csv'\n",
    "probs_0dot6_csv = '../eval/prob_resnet_spec_eval_FGSM_0dot8.csv'\n",
    "probs_0dot8_csv = '../eval/prob_resnet_spec_eval_FGSM_0dot8.csv'\n",
    "probs_1dot0_csv = '../eval/prob_resnet_spec_eval_FGSM_1dot0.csv'\n",
    "probs_2dot0_csv = '../eval/prob_resnet_spec_eval_FGSM_2dot0.csv' \n",
    "probs_3dot0_csv = '../eval/prob_resnet_spec_eval_FGSM_3dot0.csv'\n",
    "\n",
    "\n",
    "# check the lengths\n",
    "probs_clean = pd.read_csv(probs_clean_csv, header=0, engine='python')\n",
    "probs_0dot0 = pd.read_csv(probs_0dot0_csv, header=0, engine='python')\n",
    "probs_0dot2 = pd.read_csv(probs_0dot2_csv, header=0, engine='python')\n",
    "probs_0dot4 = pd.read_csv(probs_0dot4_csv, header=0, engine='python')\n",
    "probs_0dot6 = pd.read_csv(probs_0dot8_csv, header=0, engine='python')\n",
    "probs_0dot8 = pd.read_csv(probs_0dot8_csv, header=0, engine='python')\n",
    "probs_1dot0 = pd.read_csv(probs_1dot0_csv, header=0, engine='python')\n",
    "probs_2dot0 = pd.read_csv(probs_2dot0_csv, header=0, engine='python')\n",
    "probs_3dot0 = pd.read_csv(probs_3dot0_csv, header=0, engine='python')\n",
    "\n",
    "\n",
    "\n",
    "if len(probs_clean) == len(probs_0dot2) == len(probs_0dot4) == len(probs_0dot6) == len(probs_0dot8) == len(probs_1dot0) == len(probs_2dot0) == len(probs_3dot0):\n",
    "    print(f'Lengths are okay: {len(probs_clean)-1}')\n",
    "else:\n",
    "    sys.exit('Lengths are not okay')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:30:47.839745Z",
     "start_time": "2024-06-05T20:30:41.723751Z"
    }
   },
   "id": "2e0dfecac7f3448f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probs_clean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:31:45.840527Z",
     "start_time": "2024-06-05T20:31:45.834162Z"
    }
   },
   "id": "10c61b0b4e7132de",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ground truth file of evaluation dataset (ASVSpoof2019)\n",
    "config_path = '../config/residualnet_train_config.yaml'\n",
    "config = read_yaml(config_path)\n",
    "df_eval = pd.read_csv(os.path.join('..', config['df_eval_path']))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d24f73447dcc84d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_eval[:3]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2053e83be478ee37",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Extract PREDICTED labels in the same order given by df_eval_19!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7f74d9862c4bee7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_id(file_path):\n",
    "    match = re.search(r'LA_E_(\\d+)', file_path)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "    \n",
    "    \n",
    "def pred_probabilities(file2_path):\n",
    "    # read df_eval_19\n",
    "    file1_path = '../data/df_eval_19.csv'\n",
    "    \n",
    "    file1_ids = []\n",
    "    with open(file1_path, 'r') as file1:\n",
    "        csv_reader = csv.reader(file1)\n",
    "        for row in csv_reader:\n",
    "            file_id = extract_id(row[1])\n",
    "            if file_id:\n",
    "                file1_ids.append(file_id)\n",
    "    \n",
    "    # read second file and store data in a dictionary\n",
    "    file2_data = {}\n",
    "    with open(file2_path, 'r') as file2:\n",
    "        csv_reader = csv.reader(file2)\n",
    "        for row in csv_reader:\n",
    "            file_id = extract_id(row[0])\n",
    "            if file_id:\n",
    "                file2_data[file_id] = (float(row[1]), float(row[2]))\n",
    "                \n",
    "    output_array = []\n",
    "    for file_id in file1_ids:\n",
    "        if file_id in file2_data:\n",
    "            col2, col3 = file2_data[file_id]\n",
    "            output_array.append(0 if col2>col3 else 1)\n",
    "                \n",
    "    return output_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T20:30:47.851331Z",
     "start_time": "2024-06-05T20:30:47.850915Z"
    }
   },
   "id": "8dfdde730fa5603a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Accuracies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e461ee5cbb054fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# the score values .csv uses a space as a delimiter between the file path and the score\n",
    "\n",
    "# def convert_probs_to_labels(csv_file):\n",
    "#     binary_list = []\n",
    "#     \n",
    "#     with open(csv_file, 'r') as file:\n",
    "#         reader = csv.reader(file)\n",
    "#         next(reader) # skip the header\n",
    "#         for line in reader:\n",
    "#             val_1 = float(line[1])\n",
    "#             val_2 = float(line[2])\n",
    "#             \n",
    "#             try:\n",
    "#                 if val_1 > val_2:\n",
    "#                     binary_list.append(0)\n",
    "#                 else:\n",
    "#                     binary_list.append(1)\n",
    "#             except ValueError:\n",
    "#                 pass\n",
    "#         \n",
    "#     return binary_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c08eb7c873e49ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_labels_clean_rawnet = pred_probabilities(file2_path=probs_rawnet_clean_csv)\n",
    "pred_labels_0dot2_rawnet = pred_probabilities(file2_path=probs_rawnet_0dot2_csv)\n",
    "pred_labels_1dot0_rawnet = pred_probabilities(file2_path=probs_rawnet_1dot0_csv)\n",
    "pred_labels_2dot0_rawnet = pred_probabilities(file2_path=probs_rawnet_2dot0_csv)\n",
    "pred_labels_3dot0_rawnet = pred_probabilities(file2_path=probs_rawnet_3dot0_csv)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8f417a01f7bf50f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_labels_clean = pred_probabilities(file2_path=probs_clean_csv)\n",
    "pred_labels_0dot0 = pred_probabilities(file2_path=probs_0dot0_csv)\n",
    "pred_labels_0dot2 = pred_probabilities(file2_path=probs_0dot2_csv)\n",
    "pred_labels_0dot4 = pred_probabilities(file2_path=probs_0dot4_csv)\n",
    "pred_labels_0dot6 = pred_probabilities(file2_path=probs_0dot6_csv)\n",
    "pred_labels_0dot8 = pred_probabilities(file2_path=probs_0dot8_csv)\n",
    "pred_labels_1dot0 = pred_probabilities(file2_path=probs_1dot0_csv)\n",
    "pred_labels_2dot0 = pred_probabilities(file2_path=probs_2dot0_csv)\n",
    "pred_labels_3dot0 = pred_probabilities(file2_path=probs_3dot0_csv)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44b08a1d9c8d33f2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pred_labels_clean[:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d52ac50bacd5a7d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get the GT labels\n",
    "GT_labels = df_eval.iloc[:, -1].tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "516387f94a0af361",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Unbalanced accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66e00a28df8b80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unb_acc_rawnet_clean = accuracy_score(y_true=GT_labels, y_pred=pred_labels_clean_rawnet)\n",
    "unb_acc_rawnet_0dot2 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot2_rawnet)\n",
    "unb_acc_rawnet_1dot0 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_1dot0_rawnet)\n",
    "unb_acc_rawnet_2dot0 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_2dot0_rawnet)\n",
    "unb_acc_rawnet_3dot0 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_3dot0_rawnet)\n",
    "\n",
    "print(f'The unbalanced acc for clean set for RawNet2 is {unb_acc_rawnet_clean*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for eps=0.2 set for RawNet2 is {unb_acc_rawnet_0dot2*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for eps=1.0 set for RawNet2 is {unb_acc_rawnet_1dot0*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for eps=2.0 set for RawNet2 is {unb_acc_rawnet_2dot0*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for eps=3.0 set for RawNet2 is {unb_acc_rawnet_3dot0*100:.2f}%\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4965b486efc5670b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unb_acc_clean = accuracy_score(y_true=GT_labels, y_pred=pred_labels_clean)\n",
    "unb_acc_0dot0 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot0)\n",
    "unb_acc_0dot2 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot2)\n",
    "unb_acc_0dot4 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot4)\n",
    "unb_acc_0dot6 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot8)\n",
    "unb_acc_0dot8 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot8)\n",
    "unb_acc_1dot0 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_1dot0)\n",
    "unb_acc_2dot0 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_2dot0)\n",
    "unb_acc_3dot0 = accuracy_score(y_true=GT_labels, y_pred=pred_labels_3dot0)\n",
    "\n",
    "print(f'The unbalanced acc for clean eval set is {unb_acc_clean*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for epsilon = 0.2 set is {unb_acc_0dot2*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for epsilon = 0.4 set is {unb_acc_0dot4*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for epsilon = 0.6 set is {unb_acc_0dot6*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for epsilon = 0.8 set is {unb_acc_0dot8*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for epsilon = 1.0 set is {unb_acc_1dot0*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for epsilon = 2.0 set is {unb_acc_2dot0*100:.2f}%\\n'\n",
    "      f'The unbalanced acc for epsilon = 3.0 set is {unb_acc_3dot0*100:.2f}%')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "976020a289e74015",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unb_acc_0dot0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adaa7f8ba2dadb2a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Balanced accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ee223319e273960"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bal_acc_clean_rawnet = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_clean_rawnet)\n",
    "bal_acc_0dot2_rawnet = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot2_rawnet)\n",
    "bal_acc_1dot0_rawnet = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_1dot0_rawnet)\n",
    "bal_acc_2dot0_rawnet = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_2dot0_rawnet)\n",
    "bal_acc_3dot0_rawnet = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_3dot0_rawnet)\n",
    "\n",
    "\n",
    "print(f'The balanced acc for clean set for RawNet2 is {bal_acc_clean_rawnet*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 0.2 set for RawNet2 is {bal_acc_0dot2_rawnet*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 1.0 set for RawNet2 is {bal_acc_1dot0_rawnet*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 2.0 set for RawNet2 is {bal_acc_2dot0_rawnet*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 3.0 set for RawNet2 is {bal_acc_3dot0_rawnet*100:.2f}%\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ea1769cb741feab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bal_acc_clean = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_clean)\n",
    "bal_acc_0dot0 = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot0)\n",
    "bal_acc_0dot2 = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot2)\n",
    "bal_acc_0dot4 = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot4)\n",
    "bal_acc_0dot6 = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot6)\n",
    "bal_acc_0dot8 = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_0dot8)\n",
    "bal_acc_1dot0 = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_1dot0)\n",
    "bal_acc_2dot0 = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_2dot0)\n",
    "bal_acc_3dot0 = balanced_accuracy_score(y_true=GT_labels, y_pred=pred_labels_3dot0)\n",
    "\n",
    "print(f'The balanced acc for clean eval set is {bal_acc_clean*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 0.2 set is {bal_acc_0dot2*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 0.4 set is {bal_acc_0dot4*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 0.6 set is {bal_acc_0dot6*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 0.8 set is {bal_acc_0dot8*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 1.0 set is {bal_acc_1dot0*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 2.0 set is {bal_acc_2dot0*100:.2f}%\\n'\n",
    "      f'The balanced acc for epsilon = 3.0 set is {bal_acc_3dot0*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dbe85893dd35774",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bal_acc_0dot0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8758825e8e91ce16",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## ROC curve and AUC"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "437d1a260a27df1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_prob_pos_class_list(file2_path):\n",
    "    # read df_eval_19 and get a list of the file names\n",
    "    file1_path = '../data/df_eval_19.csv'\n",
    "    \n",
    "    file1_ids = []\n",
    "    with open(file1_path, 'r') as file1:\n",
    "        csv_reader = csv.reader(file1)\n",
    "        for row in csv_reader:\n",
    "            file_id = extract_id(row[1])\n",
    "            if file_id:\n",
    "                file1_ids.append(file_id)\n",
    "    \n",
    "    # read second file and store data in a dictionary\n",
    "    file2_data = {}\n",
    "    with open(file2_path, 'r') as file2:\n",
    "        csv_reader = csv.reader(file2)\n",
    "        for row in csv_reader:\n",
    "            file_id = extract_id(row[0])\n",
    "            if file_id:\n",
    "                file2_data[file_id] = (float(row[1]), float(row[2]))\n",
    "                \n",
    "    output_array = []\n",
    "    for file_id in file1_ids:\n",
    "        if file_id in file2_data:\n",
    "            col2, col3 = file2_data[file_id]\n",
    "            output_array.append(col3) # get the probability value\n",
    "                \n",
    "    return output_array\n",
    "\n",
    "# def create_prob_pos_class_list(csv_file):\n",
    "#     probs_pos_class = []\n",
    "#     with open(csv_file, 'r') as file:\n",
    "#         reader = csv.reader(file)\n",
    "#         next(reader) # skip the header\n",
    "#         for row in reader:\n",
    "#             val = float(row[2]) # negative\n",
    "#             probs_pos_class.append(val)\n",
    "#     return probs_pos_class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23b46a244c70e7f5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "positive_class_probs = create_prob_pos_class_list(probs_clean_csv)\n",
    "positive_class_probs_0dot2 = create_prob_pos_class_list(probs_0dot2_csv)\n",
    "positive_class_probs_0dot4 = create_prob_pos_class_list(probs_0dot4_csv)\n",
    "positive_class_probs_0dot6 = create_prob_pos_class_list(probs_0dot6_csv)\n",
    "positive_class_probs_0dot8 = create_prob_pos_class_list(probs_0dot8_csv)\n",
    "positive_class_probs_1dot0 = create_prob_pos_class_list(probs_1dot0_csv)\n",
    "positive_class_probs_2dot0 = create_prob_pos_class_list(probs_2dot0_csv)\n",
    "positive_class_probs_3dot0 = create_prob_pos_class_list(probs_3dot0_csv)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "220495e2b172c29d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "positive_class_probs_0dot2_rawnet = create_prob_pos_class_list(probs_rawnet_0dot2_csv)\n",
    "positive_class_probs_1dot0_rawnet = create_prob_pos_class_list(probs_rawnet_1dot0_csv)\n",
    "positive_class_probs_2dot0_rawnet = create_prob_pos_class_list(probs_rawnet_2dot0_csv)\n",
    "positive_class_probs_3dot0_rawnet = create_prob_pos_class_list(probs_rawnet_3dot0_csv)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26a5b39ad5810158",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "FP_clean, TP_clean, _ = roc_curve(GT_labels, positive_class_probs)\n",
    "ROC_AUC_clean = auc(FP_clean, TP_clean)\n",
    "\n",
    "FP_0dot2, TP_0dot2, _ = roc_curve(GT_labels, positive_class_probs_0dot2)\n",
    "ROC_AUC_0dot2 = auc(FP_0dot2, TP_0dot2)\n",
    "\n",
    "FP_0dot4, TP_0dot4, _ = roc_curve(GT_labels, positive_class_probs_0dot4)\n",
    "ROC_AUC_0dot4 = auc(FP_0dot4, TP_0dot4)\n",
    "\n",
    "FP_0dot6, TP_0dot6, _ = roc_curve(GT_labels, positive_class_probs_0dot6)\n",
    "ROC_AUC_0dot6 = auc(FP_0dot6, TP_0dot6)\n",
    "\n",
    "FP_0dot8, TP_0dot8, _ = roc_curve(GT_labels, positive_class_probs_0dot8)\n",
    "ROC_AUC_0dot8 = auc(FP_0dot8, TP_0dot8)\n",
    "\n",
    "FP_1dot0, TP_1dot0, _ = roc_curve(GT_labels, positive_class_probs_1dot0)\n",
    "ROC_AUC_1dot0 = auc(FP_1dot0, TP_1dot0)\n",
    "\n",
    "FP_2dot0, TP_2dot0, _ = roc_curve(GT_labels, positive_class_probs_2dot0)\n",
    "ROC_AUC_2dot0 = auc(FP_2dot0, TP_2dot0)\n",
    "\n",
    "FP_3dot0, TP_3dot0, _ = roc_curve(GT_labels, positive_class_probs_3dot0)\n",
    "ROC_AUC_3dot0 = auc(FP_3dot0, TP_3dot0)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd6cac62e264e0a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "FP_0dot2_r, TP_0dot2_r, _ = roc_curve(GT_labels, positive_class_probs_0dot2_rawnet)\n",
    "ROC_AUC_0dot2_r = auc(FP_0dot2_r, TP_0dot2_r)\n",
    "\n",
    "FP_1dot0_r, TP_1dot0_r, _ = roc_curve(GT_labels, positive_class_probs_1dot0_rawnet)\n",
    "ROC_AUC_1dot0_r = auc(FP_1dot0_r, TP_1dot0_r)\n",
    "\n",
    "FP_2dot0_r, TP_2dot0_r, _ = roc_curve(GT_labels, positive_class_probs_2dot0_rawnet)\n",
    "ROC_AUC_2dot0_r = auc(FP_2dot0_r, TP_2dot0_r)\n",
    "\n",
    "FP_3dot0_r, TP_3dot0_r, _ = roc_curve(GT_labels, positive_class_probs_3dot0_rawnet)\n",
    "ROC_AUC_3dot0_r = auc(FP_3dot0_r, TP_3dot0_r)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "571e0afad6c89128",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(FP_clean, TP_clean, color='blue', lw=1.5, label=f'Clean (AUC = {ROC_AUC_clean:.2f})')\n",
    "plt.plot(FP_0dot2, TP_0dot2, color='plum', lw=1.5, label=f'FGSM eps=0.2 (AUC = {ROC_AUC_0dot2:.2f})')\n",
    "plt.plot(FP_0dot4, TP_0dot4, color='orange', lw=1.5, label=f'FGSM eps=0.4 (AUC = {ROC_AUC_0dot4:.2f})')\n",
    "plt.plot(FP_0dot6, TP_0dot6, color='gold', lw=1.5, label=f'FGSM eps=0.6 (AUC = {ROC_AUC_0dot6:.2f})')\n",
    "plt.plot(FP_0dot8, TP_0dot8, color='cyan', lw=1.5, label=f'FGSM eps=0.8 (AUC = {ROC_AUC_0dot8:.2f})')\n",
    "plt.plot(FP_1dot0, TP_1dot0, color='pink', lw=1.5, label=f'FGSM eps=1.0 (AUC = {ROC_AUC_1dot0:.2f})')\n",
    "plt.plot(FP_2dot0, TP_2dot0, color='green', lw=1.5, label=f'FGSM eps=2.0 (AUC = {ROC_AUC_2dot0:.2f})')\n",
    "plt.plot(FP_3dot0, TP_3dot0, color='red', lw=1.5, label=f'FGSM eps=3.0 (AUC = {ROC_AUC_3dot0:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "319426c1a55e3415",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.plot(FP_clean, TP_clean, color='blue', lw=1.5, label=f'Clean (AUC = {ROC_AUC_clean:.2f})')\n",
    "plt.plot(FP_0dot2_r, TP_0dot2_r, color='plum', lw=1.5, label=f'FGSM eps=0.2 (AUC = {ROC_AUC_0dot2_r:.2f})')\n",
    "plt.plot(FP_1dot0_r, TP_1dot0_r, color='pink', lw=1.5, label=f'FGSM eps=1.0 (AUC = {ROC_AUC_1dot0_r:.2f})')\n",
    "plt.plot(FP_2dot0_r, TP_2dot0_r, color='green', lw=1.5, label=f'FGSM eps=2.0 (AUC = {ROC_AUC_2dot0_r:.2f})')\n",
    "plt.plot(FP_3dot0_r, TP_3dot0_r, color='red', lw=1.5, label=f'FGSM eps=3.0 (AUC = {ROC_AUC_3dot0_r:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve _ RAWNET2')\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad6dc5410c5ea6f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "#https://yangcha.github.io/EER-ROC/\n",
    "\n",
    "def compute_eer(fpr, tpr):\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    return eer\n",
    "\n",
    "\n",
    "print(f'EER clean dataset : {compute_eer(FP_clean, TP_clean)*100:.2f}%\\n'\n",
    "      f'EER eps = 0.2 : {compute_eer(FP_0dot2, TP_0dot2)*100:.2f}%\\n'\n",
    "      f'EER eps = 0.4 : {compute_eer(FP_0dot4, TP_0dot4)*100:.2f}%\\n'\n",
    "      f'EER eps = 0.6 : {compute_eer(FP_0dot6, TP_0dot6)*100:.2f}%\\n'\n",
    "      f'EER eps = 0.8 : {compute_eer(FP_0dot8, TP_0dot8)*100:.2f}%\\n'\n",
    "      f'EER eps = 1.0 : {compute_eer(FP_1dot0, TP_1dot0)*100:.2f}%\\n'\n",
    "      f'EER eps = 2.0 : {compute_eer(FP_2dot0, TP_2dot0)*100:.2f}%\\n'\n",
    "      f'EER eps = 3.0 : {compute_eer(FP_3dot0, TP_3dot0)*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52b8ccc3c6a087d3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## % of audios with different predictions (wrt clean dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "899d232cd5d7ea43"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def percentage_different(list1, list2):\n",
    "#     if len(list1) != len(list2):\n",
    "#         raise ValueError('Lists have different lengths')\n",
    "#     num_different = sum(1 for x,y in zip(list1, list2) if x!=y)\n",
    "#     total_elements = len(list1)\n",
    "#     percentage = (num_different/total_elements)*100\n",
    "#     return percentage\n",
    "# \n",
    "# print(f'The % of audios with different predictions for eps = 1.0 is {percentage_different(GT_labels, pred_labels_1dot0):.2f}%\\n'\n",
    "#       f'The % of audios with different predictions for eps = 2.0 is {percentage_different(GT_labels, pred_labels_2dot0):.2f}%\\n'\n",
    "#       f'The % of audios with different predictions for eps = 3.0 is {percentage_different(GT_labels, pred_labels_3dot0):.2f}%')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7224d8012910982",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Confusion matrix\n",
    "* TN true negative, actual class was 0 (BF) and predicted as 0\n",
    "* FP false positive, actual class was 0, but predicted as 1 (deep fake)\n",
    "* FN false negative, actual class was 1, but predicted as 0\n",
    "* TP true positive, actual class was 1 and predicted as 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48f4b18197487837"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# [ TN    FP\n",
    "#   FN    TP ]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c85846e97bd9153c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cm_clean = confusion_matrix(GT_labels, pred_labels_clean)\n",
    "print(cm_clean)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c996f58fa3fe1ff",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cm_1dot0 = confusion_matrix(GT_labels, pred_labels_1dot0)\n",
    "print(cm_1dot0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dce79440b989ffe2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cm_2dot0 = confusion_matrix(GT_labels, pred_labels_2dot0)\n",
    "print(cm_2dot0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ee31f83edba882b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cm_3dot0 = confusion_matrix(GT_labels, pred_labels_3dot0)\n",
    "print(cm_3dot0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33e2e1c3a5887ed0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cm_0dot2 = confusion_matrix(GT_labels, pred_labels_0dot2)\n",
    "cm_0dot4 = confusion_matrix(GT_labels, pred_labels_0dot4)\n",
    "cm_0dot6 = confusion_matrix(GT_labels, pred_labels_0dot6)\n",
    "cm_0dot8 = confusion_matrix(GT_labels, pred_labels_0dot8)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcbdd93d1cd3a4e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "TN = [cm_clean[0,0], cm_0dot2[0,0], cm_0dot4[0,0], cm_0dot6[0,0], cm_0dot8[0,0], cm_1dot0[0,0], cm_2dot0[0,0], cm_3dot0[0,0]]\n",
    "FP = [cm_clean[0,1], cm_0dot2[0,1], cm_0dot4[0,1], cm_0dot6[0,1], cm_0dot8[0,1], cm_1dot0[0,1], cm_2dot0[0,1], cm_3dot0[0,1]]\n",
    "FN = [cm_clean[1,0], cm_0dot2[1,0], cm_0dot4[1,0], cm_0dot6[1,0], cm_0dot8[1,0], cm_1dot0[1,0], cm_2dot0[1,0], cm_3dot0[1,0]]\n",
    "TP = [cm_clean[1,1], cm_0dot2[1,1], cm_0dot4[1,1], cm_0dot6[1,1], cm_0dot8[1,1], cm_1dot0[1,1], cm_2dot0[1,1], cm_3dot0[1,1]]\n",
    "eps = [0.0, 0.2, 0.4, 0.8, 1.0, 2.0, 3.0]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(eps, TN, color='blue', lw=1.5, label=f'True Negative')\n",
    "plt.plot(eps, FP, color='red', lw=1.5, label=f'False Positive')\n",
    "plt.plot(eps, FN, color='green', lw=1.5, label=f'False Negative')\n",
    "plt.plot(eps, TP, color='orange', lw=1.5, label=f'True Positive')\n",
    "\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.title('Confusion matrices')\n",
    "plt.xticks(eps)\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4295c3af00772524",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "TN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d553651389eb543",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Check one single file given the path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463983210e511a4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_file_given_path(file_path, model_to_use)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c35a899c515cd36"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation scores\n",
    "Using the file ../eval/scores_resnet_spec_eval.csv I evaluate the model performance of the evaluation process, performed on the ASVSpoof2021 dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e72e876c1cd569fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing the % of correct predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e997dc3e96b5904"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from src.utils import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:24.941430100Z",
     "start_time": "2024-05-15T09:00:21.479672500Z"
    }
   },
   "id": "142b35be13b9255",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "config_path = '../config/residualnet_train_config.yaml'\n",
    "config = read_yaml(config_path)\n",
    "df_eval = pd.read_csv(os.path.join('..', config['df_eval_path']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:25.481420200Z",
     "start_time": "2024-05-15T09:00:24.941430100Z"
    }
   },
   "id": "1d24f73447dcc84d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "csv_score_file = '../eval/scores_resnet_spec_eval.csv'  \n",
    "scores_eval = pd.read_csv(csv_score_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:25.753570300Z",
     "start_time": "2024-05-15T09:00:25.482422Z"
    }
   },
   "id": "bc0f2f5e23c73129",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the evaluation file list is 611829\n",
      "The length of the evaluation score list is 249431\n"
     ]
    }
   ],
   "source": [
    "print(f'The length of the evaluation file list is {len(df_eval)}\\nThe length of the evaluation score list is {len(scores_eval)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:25.759569600Z",
     "start_time": "2024-05-15T09:00:25.757575700Z"
    }
   },
   "id": "55541c821c668631",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "example: <br>\n",
    "higher log probability ==> predicted class\n",
    "if [score 0]=-2 and [score 1]=-3 then it means that the predicted class is class 0 <br>\n",
    "[score] = -2+3 = 1 > 0 --> class 0\n",
    "<br>\n",
    "###########\n",
    "<br>\n",
    "if [score 0]=-3 and [score 1]=-2 then it means that the predicted class is class 1 <br>\n",
    "[score] = -3+2 = -1 < 0 --> class 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8631c469c2221c1a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# the score values .csv uses a space as a delimiter between the file path and the score\n",
    "\n",
    "def convert_column_to_binary(csv_file):\n",
    "    binary_list = []\n",
    "    \n",
    "    with open(csv_file, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split each line based on space \n",
    "            parts = line.strip().split()\n",
    "            value = float(parts[1])\n",
    "            \n",
    "            try:\n",
    "                if value > 0:\n",
    "                    binary_list.append(0)\n",
    "                else:\n",
    "                    binary_list.append(1)\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "    return binary_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:25.853083800Z",
     "start_time": "2024-05-15T09:00:25.761570900Z"
    }
   },
   "id": "7c08eb7c873e49ef",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scores_binary_list = convert_column_to_binary(csv_score_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:26.101811800Z",
     "start_time": "2024-05-15T09:00:25.861083700Z"
    }
   },
   "id": "44b08a1d9c8d33f2",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# column at which I have the GT labels\n",
    "csv_column_index = 2\n",
    "csv_GT_file = '../data/df_eval.csv'\n",
    "\n",
    "with open(csv_GT_file, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    csv_GT_values = [int(row[csv_column_index]) for row in reader]\n",
    "    \n",
    "total_values = len(scores_binary_list)\n",
    "identical_count = sum(1 for x,y in zip(scores_binary_list, csv_GT_values) if x==y)\n",
    "percentage_identical = (identical_count/total_values)*100\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:26.498426200Z",
     "start_time": "2024-05-15T09:00:26.102806Z"
    }
   },
   "id": "976020a289e74015",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of GT values is 611829\n",
      "The nuber of scores we got is 249432\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of GT values is {len(csv_GT_values)}')\n",
    "print(f'The nuber of scores we got is {len(scores_binary_list)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:26.503427200Z",
     "start_time": "2024-05-15T09:00:26.499425900Z"
    }
   },
   "id": "5d97a9ee5f59e9b9",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "89.26841784534463"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_identical"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:26.614315600Z",
     "start_time": "2024-05-15T09:00:26.500426600Z"
    }
   },
   "id": "c50202531fff47af",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computingh the ROC and EER"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "437d1a260a27df1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:26.696397300Z",
     "start_time": "2024-05-15T09:00:26.612316Z"
    }
   },
   "id": "a9d09ca033b027b3",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_eer(y_true, y_score):\n",
    "    # compute the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    \n",
    "    # find threshold\n",
    "    eer_threshold_idx = np.argmin(np.abs(fpr-(1-tpr)))\n",
    "    eer_threshold = thresholds[eer_threshold_idx]\n",
    "    \n",
    "    # Calculate EER (FPR or TPR at the EER threshold)\n",
    "    eer_fpr = fpr[eer_threshold_idx]\n",
    "    eer_tpr = tpr[eer_threshold_idx]\n",
    "    eer = (eer_fpr + (1 - eer_tpr)) / 2.0\n",
    "    \n",
    "    return eer, eer_threshold"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:26.783401100Z",
     "start_time": "2024-05-15T09:00:26.704397400Z"
    }
   },
   "id": "4e7406923eca13c1",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [611829, 249432]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m eer, eer_threshold \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_eer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcsv_GT_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscores_binary_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 3\u001B[0m, in \u001B[0;36mcompute_eer\u001B[0;34m(y_true, y_score)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_eer\u001B[39m(y_true, y_score):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# compute the ROC curve\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     fpr, tpr, thresholds \u001B[38;5;241m=\u001B[39m \u001B[43mroc_curve\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# find threshold\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     eer_threshold_idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmin(np\u001B[38;5;241m.\u001B[39mabs(fpr\u001B[38;5;241m-\u001B[39m(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39mtpr)))\n",
      "File \u001B[0;32m/nas/home/wwang/miniconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:214\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    210\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    211\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    212\u001B[0m         )\n\u001B[1;32m    213\u001B[0m     ):\n\u001B[0;32m--> 214\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    224\u001B[0m     )\n",
      "File \u001B[0;32m/nas/home/wwang/miniconda3/envs/thesis/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1095\u001B[0m, in \u001B[0;36mroc_curve\u001B[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001B[0m\n\u001B[1;32m    993\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m    994\u001B[0m     {\n\u001B[1;32m    995\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1004\u001B[0m     y_true, y_score, \u001B[38;5;241m*\u001B[39m, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, drop_intermediate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1005\u001B[0m ):\n\u001B[1;32m   1006\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001B[39;00m\n\u001B[1;32m   1007\u001B[0m \n\u001B[1;32m   1008\u001B[0m \u001B[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1093\u001B[0m \u001B[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001B[39;00m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1095\u001B[0m     fps, tps, thresholds \u001B[38;5;241m=\u001B[39m \u001B[43m_binary_clf_curve\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1096\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\n\u001B[1;32m   1097\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m     \u001B[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m     \u001B[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001B[39;00m\n\u001B[1;32m   1101\u001B[0m     \u001B[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1106\u001B[0m     \u001B[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m     \u001B[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drop_intermediate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fps) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[0;32m/nas/home/wwang/miniconda3/envs/thesis/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:806\u001B[0m, in \u001B[0;36m_binary_clf_curve\u001B[0;34m(y_true, y_score, pos_label, sample_weight)\u001B[0m\n\u001B[1;32m    803\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m pos_label \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)):\n\u001B[1;32m    804\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m format is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(y_type))\n\u001B[0;32m--> 806\u001B[0m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    807\u001B[0m y_true \u001B[38;5;241m=\u001B[39m column_or_1d(y_true)\n\u001B[1;32m    808\u001B[0m y_score \u001B[38;5;241m=\u001B[39m column_or_1d(y_score)\n",
      "File \u001B[0;32m/nas/home/wwang/miniconda3/envs/thesis/lib/python3.11/site-packages/sklearn/utils/validation.py:407\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    405\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 407\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    408\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    409\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[1;32m    410\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [611829, 249432]"
     ]
    }
   ],
   "source": [
    "eer, eer_threshold = compute_eer(csv_GT_values, scores_binary_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T09:00:27.324163800Z",
     "start_time": "2024-05-15T09:00:26.787401700Z"
    }
   },
   "id": "33ed15b2ca7aac95",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "eer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-15T09:00:27.318155900Z"
    }
   },
   "id": "2634bf5d0a5d75ac",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing the confusion matrix\n",
    "* TN true negative, actual class was 0 (BF) and predicted as 0\n",
    "* FP false positive, actual class was 0, but predicted as 1 (deep fake)\n",
    "* FN false negative, actual class was 1, but predicted as 0\n",
    "* TP true positive, actual class was 1 and predicted as 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48f4b18197487837"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-15T09:00:27.320154500Z"
    }
   },
   "id": "c85846e97bd9153c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cm = confusion_matrix(csv_GT_values, scores_binary_list)\n",
    "print(cm)\n",
    "\n",
    "# [ TN    FP\n",
    "#   FN    TP ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-15T09:00:27.320154500Z"
    }
   },
   "id": "7c996f58fa3fe1ff",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing the indices of wrong predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "350964644441d7cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_different_indices(list1, list2):\n",
    "    if len(list1) != len(list2):\n",
    "        raise ValueError\n",
    "    diff_idx = [i for i, (x,y) in enumerate(zip(list1, list2)) if x!=y]\n",
    "    return diff_idx\n",
    "\n",
    "wrong_preds_idx = find_different_indices(csv_GT_values, scores_binary_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-15T09:00:27.321155600Z"
    }
   },
   "id": "cf5ee06e69ad88f0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "wrong_preds_idx[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-15T09:00:27.329156400Z"
    }
   },
   "id": "b669d88d1e9fd61e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-15T09:00:27.330156400Z"
    }
   },
   "id": "b7ea0e98d6e4deb1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
